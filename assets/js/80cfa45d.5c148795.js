"use strict";(self.webpackChunkdocsite_poc_github_io=self.webpackChunkdocsite_poc_github_io||[]).push([[55445],{3905:(e,t,o)=>{o.d(t,{Zo:()=>l,kt:()=>w});var n=o(67294);function r(e,t,o){return t in e?Object.defineProperty(e,t,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[t]=o,e}function p(e,t){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),o.push.apply(o,n)}return o}function a(e){for(var t=1;t<arguments.length;t++){var o=null!=arguments[t]?arguments[t]:{};t%2?p(Object(o),!0).forEach((function(t){r(e,t,o[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):p(Object(o)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(o,t))}))}return e}function s(e,t){if(null==e)return{};var o,n,r=function(e,t){if(null==e)return{};var o,n,r={},p=Object.keys(e);for(n=0;n<p.length;n++)o=p[n],t.indexOf(o)>=0||(r[o]=e[o]);return r}(e,t);if(Object.getOwnPropertySymbols){var p=Object.getOwnPropertySymbols(e);for(n=0;n<p.length;n++)o=p[n],t.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(r[o]=e[o])}return r}var c=n.createContext({}),i=function(e){var t=n.useContext(c),o=t;return e&&(o="function"==typeof e?e(t):a(a({},t),e)),o},l=function(e){var t=i(e.components);return n.createElement(c.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var o=e.components,r=e.mdxType,p=e.originalType,c=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),d=i(o),w=r,g=d["".concat(c,".").concat(w)]||d[w]||u[w]||p;return o?n.createElement(g,a(a({ref:t},l),{},{components:o})):n.createElement(g,a({ref:t},l))}));function w(e,t){var o=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var p=o.length,a=new Array(p);a[0]=d;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s.mdxType="string"==typeof e?e:r,a[1]=s;for(var i=2;i<p;i++)a[i]=o[i];return n.createElement.apply(null,a)}return n.createElement.apply(null,o)}d.displayName="MDXCreateElement"},6236:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>p,metadata:()=>s,toc:()=>i});var n=o(87462),r=(o(67294),o(3905));const p={title:"Setup the collector (GCP)",date:"2020-02-27",sidebar_position:0},a=void 0,s={unversionedId:"migrated/getting-started-on-snowplow-open-source/setup-snowplow-on-gcp/setup-the-snowplow-collector/index",id:"migrated/getting-started-on-snowplow-open-source/setup-snowplow-on-gcp/setup-the-snowplow-collector/index",title:"Setup the collector (GCP)",description:"On a GCP pipeline, the Snowplow Stream Collector receives events sent over HTTP(S), and writes them a raw Pub/Sub topic. From there, the data is picked up and processed by the Snowplow validation and enrichment job.",source:"@site/docs/migrated/getting-started-on-snowplow-open-source/setup-snowplow-on-gcp/setup-the-snowplow-collector/index.md",sourceDirName:"migrated/getting-started-on-snowplow-open-source/setup-snowplow-on-gcp/setup-the-snowplow-collector",slug:"/migrated/getting-started-on-snowplow-open-source/setup-snowplow-on-gcp/setup-the-snowplow-collector/",permalink:"/docs/migrated/getting-started-on-snowplow-open-source/setup-snowplow-on-gcp/setup-the-snowplow-collector/",draft:!1,editUrl:"https://github.com/snowplow/snowplow.github.io/tree/main/docs/migrated/getting-started-on-snowplow-open-source/setup-snowplow-on-gcp/setup-the-snowplow-collector/index.md",tags:[],version:"current",lastUpdatedAt:1660570896,formattedLastUpdatedAt:"Aug 15, 2022",sidebarPosition:0,frontMatter:{title:"Setup the collector (GCP)",date:"2020-02-27",sidebar_position:0},sidebar:"tutorialSidebar",previous:{title:"Setup Snowplow Open Source on GCP",permalink:"/docs/migrated/getting-started-on-snowplow-open-source/setup-snowplow-on-gcp/"},next:{title:"Setup the Pub/Sub topics",permalink:"/docs/migrated/getting-started-on-snowplow-open-source/setup-snowplow-on-gcp/setup-the-snowplow-collector/setup-the-pub-sub-topics/"}},c={},i=[],l={toc:i};function u(e){let{components:t,...o}=e;return(0,r.kt)("wrapper",(0,n.Z)({},l,o,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"On a GCP pipeline, the Snowplow Stream Collector receives events sent over HTTP(S), and writes them a raw Pub/Sub topic. From there, the data is picked up and processed by the Snowplow validation and enrichment job."),(0,r.kt)("p",null,"The main ",(0,r.kt)("a",{parentName:"p",href:"/docs/migrated/pipeline-components-and-applications/stream-collector/"},"collector documentation")," describes the core concepts of how the collector works, and the configuration options when running it."),(0,r.kt)("p",null,"In this guide for GCP we are going to:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Setup the Pub/Sub topics required: A good topic for data that is successfully processed by the collector, and a bad one in case any data is not successfully processed."),(0,r.kt)("li",{parentName:"ol"},"Setup and run the collector application as a single instance VM (e.g. for a development environment)"),(0,r.kt)("li",{parentName:"ol"},"Setup and run the collector as an autoscaling group of instances behind a load balancer (recommended for production)")))}u.isMDXComponent=!0}}]);